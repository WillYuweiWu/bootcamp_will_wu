{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a8bd807",
   "metadata": {},
   "source": [
    "# Stage 13 Homework Starter — Productization\n",
    "\n",
    "## Objective\n",
    "Deploy your trained model as a **reusable, handoff-ready API or dashboard** and finalize your project for reproducibility and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582e028",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Create a mock, very basic analysis in a notebook.\n",
    "2. Clean your notebook by removing exploratory cells and documenting your code.\n",
    "3. Move reusable functions into `/src/`.\n",
    "4. Load your trained model from Stage 12 or earlier stages.\n",
    "5. Pickle/save the model and test reload.\n",
    "6. Implement **either**:\n",
    "   - Flask API with `/predict` endpoint and optional parameters\n",
    "   - Streamlit or Dash dashboard for user interaction\n",
    "7. Include:\n",
    "   - Error handling for invalid inputs\n",
    "   - `requirements.txt` for reproducibility\n",
    "   - Documentation in `README.md`\n",
    "8. Test your deployment locally and provide evidence.\n",
    "9. Organize project folders and finalize notebooks for handoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e003adc",
   "metadata": {},
   "source": [
    "## 1. Create mock, very basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fadda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vix_close</th>\n",
       "      <th>vix_high</th>\n",
       "      <th>vix_low</th>\n",
       "      <th>vix_open</th>\n",
       "      <th>sp500_close</th>\n",
       "      <th>sp500_high</th>\n",
       "      <th>sp500_low</th>\n",
       "      <th>sp500_open</th>\n",
       "      <th>sp500_volume</th>\n",
       "      <th>log_sp500_close</th>\n",
       "      <th>vix_delta</th>\n",
       "      <th>vix_spread</th>\n",
       "      <th>sp500_delta</th>\n",
       "      <th>sp500_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>19.350000</td>\n",
       "      <td>21.639999</td>\n",
       "      <td>19.10</td>\n",
       "      <td>20.549999</td>\n",
       "      <td>2887.939941</td>\n",
       "      <td>2890.030029</td>\n",
       "      <td>2853.050049</td>\n",
       "      <td>2861.280029</td>\n",
       "      <td>3102480000</td>\n",
       "      <td>7.968299</td>\n",
       "      <td>-1.199999</td>\n",
       "      <td>2.539999</td>\n",
       "      <td>26.659912</td>\n",
       "      <td>36.979980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>17.879999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>17.60</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>2924.580078</td>\n",
       "      <td>2930.500000</td>\n",
       "      <td>2905.669922</td>\n",
       "      <td>2910.370117</td>\n",
       "      <td>3177150000</td>\n",
       "      <td>7.980906</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>14.209961</td>\n",
       "      <td>24.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>19.180000</td>\n",
       "      <td>17.09</td>\n",
       "      <td>17.940001</td>\n",
       "      <td>2926.459961</td>\n",
       "      <td>2940.429932</td>\n",
       "      <td>2913.320068</td>\n",
       "      <td>2937.090088</td>\n",
       "      <td>3009910000</td>\n",
       "      <td>7.981549</td>\n",
       "      <td>1.039999</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>-10.630127</td>\n",
       "      <td>27.109863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>19.41</td>\n",
       "      <td>20.959999</td>\n",
       "      <td>2906.270020</td>\n",
       "      <td>2914.389893</td>\n",
       "      <td>2891.850098</td>\n",
       "      <td>2909.010010</td>\n",
       "      <td>3427830000</td>\n",
       "      <td>7.974626</td>\n",
       "      <td>-1.299999</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>-2.739990</td>\n",
       "      <td>22.539795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>17.330000</td>\n",
       "      <td>18.830000</td>\n",
       "      <td>17.26</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>2937.780029</td>\n",
       "      <td>2938.840088</td>\n",
       "      <td>2921.860107</td>\n",
       "      <td>2924.669922</td>\n",
       "      <td>3167900000</td>\n",
       "      <td>7.985409</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>13.110107</td>\n",
       "      <td>16.979980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vix_close   vix_high  vix_low   vix_open  sp500_close  \\\n",
       "0 2019-08-28  19.350000  21.639999    19.10  20.549999  2887.939941   \n",
       "1 2019-08-29  17.879999  19.200001    17.60  19.020000  2924.580078   \n",
       "2 2019-08-30  18.980000  19.180000    17.09  17.940001  2926.459961   \n",
       "3 2019-09-03  19.660000  21.150000    19.41  20.959999  2906.270020   \n",
       "4 2019-09-04  17.330000  18.830000    17.26  18.230000  2937.780029   \n",
       "\n",
       "    sp500_high    sp500_low   sp500_open  sp500_volume  log_sp500_close  \\\n",
       "0  2890.030029  2853.050049  2861.280029    3102480000         7.968299   \n",
       "1  2930.500000  2905.669922  2910.370117    3177150000         7.980906   \n",
       "2  2940.429932  2913.320068  2937.090088    3009910000         7.981549   \n",
       "3  2914.389893  2891.850098  2909.010010    3427830000         7.974626   \n",
       "4  2938.840088  2921.860107  2924.669922    3167900000         7.985409   \n",
       "\n",
       "   vix_delta  vix_spread  sp500_delta  sp500_spread  \n",
       "0  -1.199999    2.539999    26.659912     36.979980  \n",
       "1  -1.140001    1.600000    14.209961     24.830078  \n",
       "2   1.039999    2.090000   -10.630127     27.109863  \n",
       "3  -1.299999    1.740000    -2.739990     22.539795  \n",
       "4  -0.900000    1.570000    13.110107     16.979980  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../project/data/processed/VIX_S&P500_features.csv', parse_dates = ['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e08488",
   "metadata": {},
   "source": [
    "## 2. Notebook Cleanup\n",
    "Remove exploratory cells and document your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3865724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook cleaned and ready for handoff.\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook cleaned and ready for handoff.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a613c26",
   "metadata": {},
   "source": [
    "## 3. Move reusable functions to /src/\n",
    "Create src/utils.py and store functions there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16820e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/utils.py successfully implemented.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(''))\n",
    "from src.utils import *\n",
    "\n",
    "print('src/utils.py successfully implemented.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68b6de",
   "metadata": {},
   "source": [
    "## 4. Folder Structure Reminder\n",
    "\n",
    "Ensure your project uses a clean folder structure:\n",
    "```\n",
    "project/\n",
    "  data/\n",
    "  notebooks/\n",
    "  src/\n",
    "  reports/\n",
    "  model/\n",
    "  README.md\n",
    "```\n",
    "For API/Dashboard: minimal example:\n",
    "```\n",
    "project/\n",
    "    app.py\n",
    "    model.pkl\n",
    "    requirements.txt\n",
    "    README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04bdc1",
   "metadata": {},
   "source": [
    "## 5. Pickle / Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ccd1eed-5787-4bac-98fd-a27d7bd65347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R² = 0.2446, RMSE = 0.194553\n"
     ]
    }
   ],
   "source": [
    "# Transformed regression with delta & train-test split\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as st\n",
    "\n",
    "X = df[['vix_close']]\n",
    "y = df['log_sp500_close']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print(f'Baseline R² = {r2:.4f}, RMSE = {rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f00d6fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.47520556]\n",
      "[8.43615754]\n",
      "[8.39710951]\n",
      "[8.35806149]\n",
      "[8.31901347]\n",
      "[8.27996545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "os.makedirs('model', exist_ok = True)\n",
    "\n",
    "with open('model/model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)\n",
    "\n",
    "with open('model/model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "print(loaded_model.predict([[12]]))\n",
    "print(loaded_model.predict([[15]]))\n",
    "print(loaded_model.predict([[18]]))\n",
    "print(loaded_model.predict([[21]]))\n",
    "print(loaded_model.predict([[24]]))\n",
    "print(loaded_model.predict([[27]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273308d3",
   "metadata": {},
   "source": [
    "## 6. Flask API Starter\n",
    "\n",
    "### Implement Flask endpoints for /predict and /plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d07bfded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask running at http://127.0.0.1:5000  (try /health, /predict, /plot)\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (_run):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/6w/t2sqjkx12cg3m5nlk8pwxlxm0000gn/T/ipykernel_24980/2096075346.py\", line 127, in _run\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/site-packages/flask/app.py\", line 990, in run\n",
      "    run_simple(host, port, self, **options)\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py\", line 1052, in run_simple\n",
      "    inner()\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py\", line 996, in inner\n",
      "    srv = make_server(\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py\", line 847, in make_server\n",
      "    return ThreadedWSGIServer(\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/site-packages/werkzeug/serving.py\", line 740, in __init__\n",
      "    HTTPServer.__init__(self, server_address, handler)\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/socketserver.py\", line 452, in __init__\n",
      "    self.server_bind()\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/http/server.py\", line 137, in server_bind\n",
      "    socketserver.TCPServer.server_bind(self)\n",
      "  File \"/Users/willwu/anaconda3/lib/python3.10/socketserver.py\", line 466, in server_bind\n",
      "    self.socket.bind(self.server_address)\n",
      "OSError: [Errno 48] Address already in use\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "try:\n",
    "    from markupsafe import Markup, escape\n",
    "    jinja2.Markup = Markup\n",
    "    jinja2.escape = escape\n",
    "except Exception as e:\n",
    "    raise ImportError(\"markupsafe is required for Jinja2 >= 3.1\") from e\n",
    "\n",
    "import os, io, base64, threading, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "MODEL_PATH = \"model/model.pkl\"\n",
    "FEATURES = [\"vix_close\", \"log_sp500_close\"]\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    with open(MODEL_PATH, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    class _DummyModel:\n",
    "        def predict(self, X):\n",
    "            X = np.asarray(X)\n",
    "            w = np.array([0.002, -0.0001])[:X.shape[1]]\n",
    "            b = 0.05\n",
    "            return (X @ w) + b\n",
    "    model = _DummyModel()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def _validate_features_dict(d):\n",
    "    if not isinstance(d, dict):\n",
    "        return None, \"features must be a JSON object\"\n",
    "    missing = [k for k in FEATURES if k not in d]\n",
    "    if missing:\n",
    "        return None, f\"missing features: {missing}\"\n",
    "    try:\n",
    "        row = [float(d[k]) for k in FEATURES]\n",
    "    except Exception:\n",
    "        return None, \"all features must be numeric\"\n",
    "    return row, None\n",
    "\n",
    "@app.route(\"/health\", methods=[\"GET\"])\n",
    "def health():\n",
    "    return jsonify({\"ok\": True, \"model_loaded\": model is not None, \"features\": FEATURES})\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict_post():\n",
    "    payload = request.get_json(silent=True) or {}\n",
    "    feats = payload.get(\"features\")\n",
    "    if feats is None:\n",
    "        return jsonify({\"error\": \"send JSON with a 'features' object\"}), 400\n",
    "    row, err = _validate_features_dict(feats)\n",
    "    if err:\n",
    "        return jsonify({\"error\": err}), 400\n",
    "    try:\n",
    "        yhat = float(model.predict([row])[0])\n",
    "        return jsonify({\"prediction\": yhat})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/predict/<input1>\", methods=[\"GET\"])\n",
    "def predict_get_one(input1):\n",
    "    try:\n",
    "        x1 = float(input1)\n",
    "    except Exception:\n",
    "        return jsonify({\"error\": \"input1 must be numeric\"}), 400\n",
    "    row = [x1] + [0.0] * (len(FEATURES) - 1)\n",
    "    try:\n",
    "        yhat = float(model.predict([row])[0])\n",
    "        return jsonify({\"prediction\": yhat, \"features_used\": dict(zip(FEATURES, row))})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/predict/<input1>/<input2>\", methods=[\"GET\"])\n",
    "def predict_get_two(input1, input2):\n",
    "    if len(FEATURES) < 2:\n",
    "        return jsonify({\"error\": \"model expects < 2 features; use /predict/<input1>\"}), 400\n",
    "    try:\n",
    "        x1, x2 = float(input1), float(input2)\n",
    "    except Exception:\n",
    "        return jsonify({\"error\": \"both inputs must be numeric\"}), 400\n",
    "    row = [x1, x2] + [0.0] * (len(FEATURES) - 2)\n",
    "    try:\n",
    "        yhat = float(model.predict([row])[0])\n",
    "        return jsonify({\"prediction\": yhat, \"features_used\": dict(zip(FEATURES, row))})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/plot\", methods=[\"GET\"])\n",
    "def plot():\n",
    "    title = jinja2.escape(request.args.get(\"title\", \"Realized Volatility vs SPX Returns\"))\n",
    "\n",
    "    # 1. Log S&P 500 over time\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df['date'], df['log_sp500_close'])\n",
    "    ax.set_title(\"Log S&P 500 over Time\")\n",
    "    ax.set_xlabel(\"date\")\n",
    "    ax.set_ylabel(\"SPX log_sp500_close\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img_bytes = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    images_html += f'<h3>Log S&P 500 over Time</h3><img src=\"data:image/png;base64,{img_bytes}\"/><br>'\n",
    "    plt.close(fig)\n",
    "\n",
    "    # 2. VIX Over Time\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df['date'], df['vix_close'])\n",
    "    ax.set_title(\"VIX Over Time\")\n",
    "    ax.set_xlabel(\"date\")\n",
    "    ax.set_ylabel(\"vix_close\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img_bytes = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    images_html += f'<h3>VIX Over Time</h3><img src=\"data:image/png;base64,{img_bytes}\"/><br>'\n",
    "    plt.close(fig)\n",
    "\n",
    "def _run(): app.run(port=5000, debug=False, use_reloader=False)\n",
    "threading.Thread(target=_run, daemon=True).start()\n",
    "print(\"Flask running at http://127.0.0.1:5000  (try /health, /predict, /plot)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d8129",
   "metadata": {},
   "source": [
    "## 7. Testing the Flask API from Notebook\n",
    "\n",
    "### TODO: Modify examples with your actual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62ebdfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Aug/2025 14:18:56] \"\u001b[37mGET /health HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [28/Aug/2025 14:18:56] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [28/Aug/2025 14:18:56] \"\u001b[35m\u001b[1mGET /predict/15.2 HTTP/1.1\u001b[0m\" 500 -\n",
      "/Users/willwu/anaconda3/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [28/Aug/2025 14:18:56] \"\u001b[35m\u001b[1mGET /predict/15.2/5200 HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [28/Aug/2025 14:18:56] \"\u001b[37mGET /plot?title=Demo%20Chart HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health: {'features': ['vix_close', 'log_sp500_close'], 'model_loaded': True, 'ok': True}\n",
      "POST /predict: 400 {\"error\":\"missing features: ['log_sp500_close']\"}\n",
      "\n",
      "GET one: {\"error\":\"X has 2 features, but LinearRegression is expecting 1 features as input.\"}\n",
      "\n",
      "GET two: {\"error\":\"X has 2 features, but LinearRegression is expecting 1 features as input.\"}\n",
      "\n",
      "Plot HTML length: 38758\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Example feature vector\n",
    "example_features = [0.070698, 0.387695, 0.85, 0.09, 260.319, 6.9, 721.180880, -0.999462, 9.0]\n",
    "\n",
    "# POST /predict\n",
    "response = requests.post(\n",
    "    'http://127.0.0.1:5000/predict',\n",
    "    json={'features':example_features}\n",
    ")\n",
    "print(response.json())\n",
    "\n",
    "# GET /predict/<input1>\n",
    "response2 = requests.get('http://127.0.0.1:5000/predict/2.0')\n",
    "print(response2.json())\n",
    "\n",
    "# GET /predict/<input1>/<input2>\n",
    "response3 = requests.get('http://127.0.0.1:5000/predict/1.0/3.0')\n",
    "print(response3.json())\n",
    "\n",
    "# GET /plot\n",
    "response_plot = requests.get('http://127.0.0.1:5000/plot')\n",
    "display(HTML(response_plot.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140930a4",
   "metadata": {},
   "source": [
    "## 8. Optional Streamlit / Dash Dashboard\n",
    "\n",
    "### TODO: Add dashboard in a separate file (`app_streamlit.py` or `app_dash.py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb79d2d",
   "metadata": {},
   "source": [
    "## 9. Handoff Best Practices\n",
    "\n",
    "- Ensure README.md is complete and clear\n",
    "- Provide `requirements.txt` for reproducibility\n",
    "- Ensure pickled model and scripts are in correct folders\n",
    "- Verify another user can run the project end-to-end on a fresh environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
